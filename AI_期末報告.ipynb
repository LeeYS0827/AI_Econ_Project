{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![封面](AI_期末專題發表報名/封面.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目錄\n",
    "1. 選題動機\n",
    "2. 專案介紹\n",
    "3. 資料庫與資料介紹\n",
    "4. 實作規劃\n",
    "5. 文字探勘\n",
    "6. 語料預處理\n",
    "7. 模型簡介與實作\n",
    "8. 預測結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.選題動機\n",
    "    * 假貼文猖獗:輕則造成財物損失，重可造成人員傷亡\n",
    "    * NLP 分類問題應用廣泛，如: 電影評論\n",
    "    * 打擊假貼文:為眾多國家與社交媒體公司近年首要之務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.專案介紹\n",
    "## 題目啟發\n",
    "    * Kaggle Ongoing Competition\n",
    "    * 任務: 對災難性推特貼文，判斷真實性\n",
    "    * 評分: 放上Kaggle競賽平台，由平台公正資料評斷預測準確度\n",
    "## 我們的專案\n",
    "1. 介紹Kaggle資料集\n",
    "2. 介紹並比較機器學習模型: XGBoost v.s. SVC\n",
    "3. 利用TSNE降維做視覺化觀測\n",
    "4. 預測結果分析 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.資料庫與資料介紹\n",
    "## 資料庫- Kaggle 資料集\n",
    "* Train Data\n",
    "* Test Data\n",
    "\n",
    "## 資料集介紹\n",
    "![封面](AI_期末專題發表報名/投影片9.PNG)\n",
    "\n",
    "### Train data和Test data的比較\n",
    "* 由此可推測兩個data應該是來自同一個母體，所以在不同的詞的特徵都有類似分布\n",
    "    * word_count：文本中的單詞數\n",
    "    * unique_word_count：文本中唯一詞的數量\n",
    "    * stop_word_count：文本中停用詞的數量\n",
    "    * url_count：文本中的網址數\n",
    "    * mean_word_length：單詞中的平均字符數\n",
    "    * char_count：文本中的字符數\n",
    "    * punctuation_count：文本中的標點符號數\n",
    "    * hashtag_count：文本中的＃標籤數量\n",
    "    * mention_count：文本中的提及數（@）\n",
    "    \n",
    "    \n",
    "    \n",
    "* Train:**`藍色`** Test:**`橘色`**   \n",
    "![封面](AI_期末專題發表報名/資料集觀測.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.實作規劃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型分類\n",
    "![封面](AI_期末專題發表報名/投影片12.PNG)\n",
    "\n",
    "## 模型實做規劃\n",
    "![封面](AI_期末專題發表報名/投影片13.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 文字探勘 \n",
    "![封面](AI_期末專題發表報名/文字探勘.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.語料預處理 \n",
    "### 預處理: 正則表達式\n",
    "* 移除顏文字和一些怪符號\n",
    "* 移除 hashtag 的符號'#'\n",
    "* 移除人名標記\n",
    "* 移除網址\n",
    "* 全部小寫化\n",
    "* 移除無關用語: wa, ha, ve\n",
    "\n",
    "### 預處理: NLTK應用\n",
    "* 斷詞\n",
    "    * word_tokenize\n",
    "    * wordpunct_tokenize\n",
    "\n",
    "* 去停用字\n",
    "    * 停用字點\n",
    "    * 擴充停用詞表\n",
    "    \n",
    "### 文字雲\n",
    "![封面](AI_期末專題發表報名/文字雲.PNG)\n",
    "\n",
    "### BERT 句向量\n",
    "* 由於機器學習和深度學習模型只能接受數值資料，因此將文字資料利用BERT的模型，將文字資料轉成句向量\n",
    "\n",
    "### BERT 句向量視覺化\n",
    "* 利用TSNE將768維的句向量，降成二維資料判定是否能做很好的分類\n",
    "* 由Train data觀測推測，不論用任何模型做分類，推估都有不錯的表現，因為句向量壓縮到二維平面，兩類資料區分算明顯\n",
    "![封面](AI_期末專題發表報名/TSNE視覺化.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.模型簡介與實作\n",
    "## (1)SVC\n",
    "## SVC簡介\n",
    "* 一次用四個kernel來建立模型，分別為SVC、LinearSVC、rbf和poly\n",
    "* 參數: \n",
    "    * gamma: gamma值如果愈大資料點影響的範圍愈小\n",
    "    * C: C值愈大對極值忍受程度愈小\n",
    "    * 搜尋方法: 利用 Gridsearch\n",
    "\n",
    "## SVC 實作\n",
    "1. 轉句向量　Bert-as-Service\n",
    "2. 建立模型\n",
    "3. 調整參數: GridSearch\n",
    "4. 模型表現\n",
    "\n",
    "    \n",
    "## (2)XGBoost \n",
    "## XGBoost 簡介\n",
    "\n",
    "* Tree Ensemble 模型\n",
    "* 改良 GBDT: 貪心法優化目標函式增幅\n",
    "* 建構於C++，運算速度快\n",
    "* 強擴展性\n",
    "    * 算法優化: 稀疏數據處理\n",
    "    * 系統優化: 並行式和分佈式計算、核外計算\n",
    "\n",
    "### 1. Tree Boosting\n",
    "#### (1)Ensemble tree\n",
    "* 三個臭皮匠勝過一個諸葛亮\n",
    "* Boosting: 分類器之間有關連\n",
    "\n",
    "#### (2)XGBoost 有別於傳統的 GBDT\n",
    "* 懲罰項的設計\n",
    "* 增量訓練\n",
    "\n",
    "#### (3)避免過度擬合的方法\n",
    "* Shrinkage：\n",
    "     削弱當前這棵樹的影響力，類似learning rate作用\n",
    "\n",
    "\n",
    "* Column ( feature ) subsampling：這個技巧在 RF 當中也有使用到，同時也有助於加快訓練速度\n",
    "\n",
    "### 2. Split finding algorithms (切分點查找算法)\n",
    "* Exact greedy algorithm (貪心算法獲取最優切分點):\n",
    "\t列舉所有可能\n",
    "\n",
    "* Approximate algorithm (近似算法):\n",
    "\t提出了候選分割點概念\n",
    "\n",
    "* Weighted quantile sketch (分佈式加權直方圖算法):\n",
    "\t近似算法和分佈式加權算法是為了解決數據無法一次載入內存\t或者在分佈式情況下（貪心算法）效率低的問題\n",
    "    \n",
    "### 3. System Design\n",
    "* Column block for parallel learning 記憶體優化\n",
    "  內存單元 block 中，採用 CSC 格式存放，以後均可使用\n",
    "\n",
    "* Cache-aware access: 快取優化，提升算法效率\n",
    "\n",
    "* Blocks for out-of-core computation:\n",
    "   塊壓縮和塊拆分，有助於平行運算時降低資料從硬碟讀取時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 實作\n",
    "1. 轉句向量　Bert-as-Service\n",
    "2. Import XGBoost: Dmatrix, 建模\n",
    "3. 調整超參數: GridSearch\n",
    "4. 模型表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3)BERT\n",
    "## BERT 簡介\n",
    "\n",
    "* Bidirectional Encoder Representations from Transformer\n",
    "* 架構：Transformer中的Encoder\n",
    "* 傳統語言模型的變形\n",
    "* 一個能直接處理各式 NLP 任務的通用架構\n",
    "\n",
    "### 兩階段遷移學習！\n",
    "* 以LM Pretraining的方式，訓練出對自然語言有一定理解的模型\n",
    "* 用該模型做特徵擷取，或是fine-tune不同的下游監督式任務\n",
    "* 只要弄好第一步的模型，第二步就可用transfer learning來大大減低花費成本。\n",
    "\n",
    "### 預訓練任務\n",
    "1. 「克漏字填空」：學會處理每個詞在不同語境下該有的向量表示\n",
    "    * Masked Language Model, MLM\n",
    "    * 潮水「？」了，就知道誰沒穿褲子。\n",
    "2. 「下句預測」：學會處理兩個句子之間的關係\n",
    "    * Next Sentence Prediction, NSP\n",
    "    * 用處：問答系統QA、自然語言推論NLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT 實作\n",
    "* 匯入套件與檢視\n",
    "* 實作一個與BERT相容的Dataset\n",
    "* BERT的tokenizer\n",
    "\n",
    "![封面](AI_期末專題發表報名/tokenizer.png)\n",
    "\n",
    "* 一次傳一小batch的dataloader\n",
    "* 拿出一個batch看看\n",
    "* 訂定測試準確率的函式\n",
    "* 參數數量\n",
    "    * 加上去的線性分類器如滄海一粟般渺小\n",
    "* 訓練\n",
    "* 預測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 預測結果\n",
    "## 模型比較\n",
    "![封面](AI_期末專題發表報名/模型比較.png)\n",
    "\n",
    "## 模型表現分數\n",
    "![封面](AI_期末專題發表報名/模型表現分數.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![封面](AI_期末專題發表報名/末頁.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
